{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeffrey Yan\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreher always spends lot time never hurries shame physicians arent like\n"
     ]
    }
   ],
   "source": [
    "#Read reviews\n",
    "f=open(r\"ratemd.25k.all.txt\",'r',encoding='utf-8')\n",
    "input = f.readlines()\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "#add \"doctor\" and \"dr\" to stopwords\n",
    "stop.update([\"doctor\",\"dr\"])\n",
    "\n",
    "#Store lines after preprocessing:\n",
    "cleaned_lines = []\n",
    "\n",
    "for line in input:\n",
    "    curr_line = line\n",
    "    if(curr_line[0]!='D'):\n",
    "        startlen = len(\"Overall rating: \")\n",
    "        curr_line=curr_line[startlen:] #remove \"Overall rating: \"\n",
    "        ratingstr=curr_line.split(' ',1)[0]\n",
    "        curr_line = curr_line[len(ratingstr):]#remove rating from string\n",
    "        curr_line=curr_line.lstrip()#remove leading whitespaces\n",
    "        #Remove punctuation, numbers and lowercase string\n",
    "        curr_line = re.sub(r\"[^a-zA-z\\s]\",'',curr_line)\n",
    "        curr_line = curr_line.lower()\n",
    "        #Remove stopwords\n",
    "        curr_line = curr_line.split()\n",
    "        curr_line = [word for word in curr_line if not word in stop]\n",
    "        curr_line = ' '.join(curr_line)\n",
    "        ###############Lemmatization###################\n",
    "        # lemmatizer = WordNetLemmatizer()\n",
    "        # curr_line = curr_line.split()\n",
    "        # #Noun lemmatization:\n",
    "        # curr_line = [lemmatizer.lemmatize(word) for word in curr_line]\n",
    "        # #Verb lemmatization:\n",
    "        # #curr_line = [lemmatizer.lemmatize(word,\"v\") for word in curr_line]\n",
    "        # curr_line = [word for word in curr_line if not word in stop] #need to remove stopwords here\n",
    "        # curr_line = ' '.join(curr_line)\n",
    "        ###############################################\n",
    "        cleaned_lines.append(curr_line)\n",
    "\n",
    "print(cleaned_lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigelow', 'best', 'ever', 'encountered', 'great', 'demeanor', 'asks', 'tons', 'questions', 'personable', 'honest', 'would', 'love', 'family', 'possible', 'referred', 'ease', 'good', 'hands']\n",
      "Dictionary<31087 unique tokens: ['asks', 'best', 'bigelow', 'demeanor', 'ease']...>\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]\n"
     ]
    }
   ],
   "source": [
    "list_terms = list()\n",
    "#Separate words as items in list:\n",
    "for line in cleaned_lines:\n",
    "    words = line.split()\n",
    "    list_terms.append(words)\n",
    "#Create dictionary of terms\n",
    "term_dict = corpora.Dictionary(list_terms)\n",
    "print(list_terms[0])\n",
    "print(term_dict)\n",
    "#Convert into document-term matrix in sparse format\n",
    "common_corpus = [term_dict.doc2bow(text) for text in list_terms]\n",
    "print(common_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run LDA model\n",
    "#Set 1: : number of topics (k = 10), number of passes (pass = 20), and number of iterations (iterations = 2000)\n",
    "lda = LdaModel(common_corpus, num_topics=10, id2word=term_dict, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 2: number of topics (k = 20), number of passes (pass = 20), and number of iterations (iterations = 2000).\n",
    "lda2 = LdaModel(common_corpus, num_topics=20, id2word=term_dict, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 :\n",
      "god\n",
      "bless\n",
      "community\n",
      "considerate\n",
      "tissue\n",
      "augmentation\n",
      "board\n",
      "certified\n",
      "sincere\n",
      "mothers\n",
      "Topic 2 :\n",
      "time\n",
      "always\n",
      "years\n",
      "best\n",
      "patients\n",
      "staff\n",
      "care\n",
      "patient\n",
      "great\n",
      "feel\n",
      "Topic 3 :\n",
      "pain\n",
      "surgery\n",
      "life\n",
      "years\n",
      "back\n",
      "husband\n",
      "months\n",
      "diagnosed\n",
      "able\n",
      "problem\n",
      "Topic 4 :\n",
      "medical\n",
      "heart\n",
      "patient\n",
      "medicine\n",
      "patients\n",
      "physician\n",
      "cardiologist\n",
      "knowledge\n",
      "treatment\n",
      "idea\n",
      "Topic 5 :\n",
      "surgery\n",
      "cancer\n",
      "breast\n",
      "surgeon\n",
      "skin\n",
      "removed\n",
      "done\n",
      "look\n",
      "procedure\n",
      "face\n",
      "Topic 6 :\n",
      "insurance\n",
      "medical\n",
      "office\n",
      "company\n",
      "wife\n",
      "services\n",
      "tests\n",
      "rojas\n",
      "order\n",
      "procedures\n",
      "Topic 7 :\n",
      "pain\n",
      "glyman\n",
      "knee\n",
      "side\n",
      "tooth\n",
      "blood\n",
      "physical\n",
      "caused\n",
      "bed\n",
      "father\n",
      "Topic 8 :\n",
      "staff\n",
      "office\n",
      "rude\n",
      "patients\n",
      "manner\n",
      "good\n",
      "bedside\n",
      "front\n",
      "care\n",
      "worst\n",
      "Topic 9 :\n",
      "staff\n",
      "recommend\n",
      "great\n",
      "would\n",
      "highly\n",
      "excellent\n",
      "knowledgeable\n",
      "professional\n",
      "surgery\n",
      "caring\n",
      "Topic 10 :\n",
      "would\n",
      "told\n",
      "time\n",
      "get\n",
      "never\n",
      "see\n",
      "office\n",
      "back\n",
      "said\n",
      "even\n"
     ]
    }
   ],
   "source": [
    "topics = lda.show_topics(num_words=10, num_topics=10, formatted=False)\n",
    "\n",
    "#Print topics for Set 1\n",
    "for topic in topics:\n",
    "    print(\"Topic\",topic[0]+1,\":\")\n",
    "    for word in topic[1]:\n",
    "        print(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 :\n",
      "manner\n",
      "bedside\n",
      "good\n",
      "side\n",
      "bed\n",
      "great\n",
      "docs\n",
      "thinks\n",
      "timely\n",
      "respectful\n",
      "Topic 2 :\n",
      "vegas\n",
      "las\n",
      "meds\n",
      "therapy\n",
      "foot\n",
      "pain\n",
      "physical\n",
      "medication\n",
      "prescribed\n",
      "weight\n",
      "Topic 3 :\n",
      "impressed\n",
      "st\n",
      "message\n",
      "mark\n",
      "disorder\n",
      "exam\n",
      "etc\n",
      "pap\n",
      "open\n",
      "migraines\n",
      "Topic 4 :\n",
      "son\n",
      "child\n",
      "baby\n",
      "pregnancy\n",
      "children\n",
      "delivered\n",
      "love\n",
      "daughter\n",
      "kids\n",
      "sometimes\n",
      "Topic 5 :\n",
      "time\n",
      "questions\n",
      "always\n",
      "feel\n",
      "takes\n",
      "great\n",
      "really\n",
      "like\n",
      "patient\n",
      "makes\n",
      "Topic 6 :\n",
      "staff\n",
      "recommend\n",
      "would\n",
      "great\n",
      "highly\n",
      "knowledgeable\n",
      "excellent\n",
      "helpful\n",
      "professional\n",
      "anyone\n",
      "Topic 7 :\n",
      "patients\n",
      "care\n",
      "best\n",
      "years\n",
      "patient\n",
      "family\n",
      "caring\n",
      "recommend\n",
      "cares\n",
      "physician\n",
      "Topic 8 :\n",
      "years\n",
      "best\n",
      "ive\n",
      "ever\n",
      "hes\n",
      "one\n",
      "doctors\n",
      "seen\n",
      "good\n",
      "many\n",
      "Topic 9 :\n",
      "told\n",
      "would\n",
      "time\n",
      "first\n",
      "went\n",
      "could\n",
      "one\n",
      "see\n",
      "day\n",
      "even\n",
      "Topic 10 :\n",
      "mother\n",
      "father\n",
      "smart\n",
      "sense\n",
      "earth\n",
      "humor\n",
      "oral\n",
      "expertise\n",
      "brilliant\n",
      "nervous\n",
      "Topic 11 :\n",
      "patel\n",
      "cardiologist\n",
      "md\n",
      "thyroid\n",
      "biopsy\n",
      "efficient\n",
      "promptly\n",
      "refills\n",
      "scars\n",
      "board\n",
      "Topic 12 :\n",
      "cancer\n",
      "risk\n",
      "hip\n",
      "routine\n",
      "kidney\n",
      "healthy\n",
      "high\n",
      "mom\n",
      "complete\n",
      "tumor\n",
      "Topic 13 :\n",
      "surgery\n",
      "pain\n",
      "surgeon\n",
      "back\n",
      "went\n",
      "performed\n",
      "procedure\n",
      "months\n",
      "knee\n",
      "years\n",
      "Topic 14 :\n",
      "skin\n",
      "face\n",
      "nose\n",
      "looks\n",
      "natural\n",
      "turn\n",
      "look\n",
      "root\n",
      "treatments\n",
      "botox\n",
      "Topic 15 :\n",
      "insurance\n",
      "company\n",
      "pay\n",
      "medical\n",
      "money\n",
      "please\n",
      "charge\n",
      "lack\n",
      "provider\n",
      "covered\n",
      "Topic 16 :\n",
      "wait\n",
      "time\n",
      "appointment\n",
      "waiting\n",
      "minutes\n",
      "room\n",
      "hours\n",
      "hour\n",
      "see\n",
      "long\n",
      "Topic 17 :\n",
      "life\n",
      "saved\n",
      "anywhere\n",
      "else\n",
      "thanks\n",
      "quality\n",
      "highest\n",
      "medicine\n",
      "wants\n",
      "fisher\n",
      "Topic 18 :\n",
      "breast\n",
      "tooth\n",
      "personality\n",
      "satisfied\n",
      "teeth\n",
      "skilled\n",
      "informative\n",
      "prompt\n",
      "sinus\n",
      "accident\n",
      "Topic 19 :\n",
      "staff\n",
      "office\n",
      "great\n",
      "phone\n",
      "service\n",
      "practice\n",
      "rude\n",
      "calls\n",
      "front\n",
      "nice\n",
      "Topic 20 :\n",
      "office\n",
      "get\n",
      "would\n",
      "go\n",
      "never\n",
      "like\n",
      "back\n",
      "dont\n",
      "didnt\n",
      "rude\n"
     ]
    }
   ],
   "source": [
    "topics2 = lda2.show_topics(num_topics=20,num_words=10, formatted=False)\n",
    "\n",
    "#Print topics for Set 2\n",
    "for topic in topics2:\n",
    "    print(\"Topic\",topic[0]+1,\":\")\n",
    "    for word in topic[1]:\n",
    "        print(word[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
