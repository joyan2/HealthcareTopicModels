{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeffrey Yan\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.tfidfmodel import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreher always spends lot time never hurries shame physicians arent like\n"
     ]
    }
   ],
   "source": [
    "#Read reviews\n",
    "f=open(r\"ratemd.25k.all.txt\",'r',encoding='utf-8')\n",
    "input = f.readlines()\n",
    "#output format:\n",
    "# 0 reviewtext\n",
    "# 1 reviewtext\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "#add \"doctor\" and \"dr\" to stopwords\n",
    "stop.update([\"doctor\",\"dr\"])\n",
    "\n",
    "#Store lines after preprocessing:\n",
    "cleaned_lines = []\n",
    "\n",
    "for line in input:\n",
    "    curr_line = line\n",
    "    if(curr_line[0]!='D'):\n",
    "        startlen = len(\"Overall rating: \")\n",
    "        curr_line=curr_line[startlen:] #remove \"Overall rating: \"\n",
    "        ratingstr=curr_line.split(' ',1)[0]\n",
    "        curr_line = curr_line[len(ratingstr):]#remove rating from string\n",
    "        curr_line=curr_line.lstrip()#remove leading whitespaces\n",
    "        #Remove punctuation, numbers and lowercase string\n",
    "        curr_line = re.sub(r\"[^a-zA-z\\s]\",'',curr_line)\n",
    "        curr_line = curr_line.lower()\n",
    "        #Remove stopwords\n",
    "        curr_line = curr_line.split()\n",
    "        curr_line = [word for word in curr_line if not word in stop]\n",
    "        curr_line = ' '.join(curr_line)\n",
    "        cleaned_lines.append(curr_line)\n",
    "\n",
    "print(cleaned_lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigelow', 'best', 'ever', 'encountered', 'great', 'demeanor', 'asks', 'tons', 'questions', 'personable', 'honest', 'would', 'love', 'family', 'possible', 'referred', 'ease', 'good', 'hands']\n",
      "Dictionary<31087 unique tokens: ['asks', 'best', 'bigelow', 'demeanor', 'ease']...>\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]\n"
     ]
    }
   ],
   "source": [
    "list_terms = list()\n",
    "#Separate words as items in list:\n",
    "for line in cleaned_lines:\n",
    "    words = line.split()\n",
    "    list_terms.append(words)\n",
    "#Create dictionary of terms\n",
    "term_dict = corpora.Dictionary(list_terms)\n",
    "print(list_terms[0])\n",
    "print(term_dict)\n",
    "#Convert into document-term matrix in sparse format\n",
    "common_corpus = [term_dict.doc2bow(text) for text in list_terms]\n",
    "print(common_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EC: Convert to tf-idf\n",
    "tfidf = TfidfModel(common_corpus, smartirs=\"ntc\")\n",
    "tfidf_corpus = tfidf[common_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run LDA model\n",
    "#Set 1: : number of topics (k = 10), number of passes (pass = 20), and number of iterations (iterations = 2000)\n",
    "lda = LdaModel(tfidf_corpus, num_topics=10, id2word=term_dict, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 2: number of topics (k = 20), number of passes (pass = 20), and number of iterations (iterations = 2000).\n",
    "lda2 = LdaModel(tfidf_corpus, num_topics=20, id2word=term_dict, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 :\n",
      "fisher\n",
      "unfriendly\n",
      "diagnostician\n",
      "complain\n",
      "root\n",
      "understands\n",
      "trained\n",
      "average\n",
      "mental\n",
      "sympathetic\n",
      "Topic 2 :\n",
      "worth\n",
      "spend\n",
      "skilled\n",
      "walked\n",
      "paid\n",
      "ordered\n",
      "father\n",
      "pediatrician\n",
      "personally\n",
      "comments\n",
      "Topic 3 :\n",
      "vegas\n",
      "las\n",
      "recomend\n",
      "comeau\n",
      "turn\n",
      "stent\n",
      "responsive\n",
      "students\n",
      "greatful\n",
      "single\n",
      "Topic 4 :\n",
      "uncaring\n",
      "earth\n",
      "end\n",
      "throat\n",
      "foot\n",
      "mean\n",
      "ent\n",
      "husbands\n",
      "insensitive\n",
      "unless\n",
      "Topic 5 :\n",
      "couple\n",
      "dad\n",
      "calm\n",
      "certified\n",
      "non\n",
      "retired\n",
      "till\n",
      "arthritis\n",
      "credit\n",
      "pusher\n",
      "Topic 6 :\n",
      "disorder\n",
      "theres\n",
      "aloof\n",
      "avoided\n",
      "texas\n",
      "rushing\n",
      "hasnt\n",
      "reccommend\n",
      "calming\n",
      "weakness\n",
      "Topic 7 :\n",
      "staff\n",
      "great\n",
      "time\n",
      "office\n",
      "would\n",
      "good\n",
      "best\n",
      "recommend\n",
      "always\n",
      "care\n",
      "Topic 8 :\n",
      "dental\n",
      "price\n",
      "helpfull\n",
      "class\n",
      "pains\n",
      "feet\n",
      "lift\n",
      "trustworthy\n",
      "language\n",
      "drop\n",
      "Topic 9 :\n",
      "highest\n",
      "appropriate\n",
      "superb\n",
      "gp\n",
      "effective\n",
      "meticulous\n",
      "thompson\n",
      "twenty\n",
      "west\n",
      "contacting\n",
      "Topic 10 :\n",
      "punctual\n",
      "brown\n",
      "efficient\n",
      "informative\n",
      "tooth\n",
      "mind\n",
      "considerate\n",
      "gentle\n",
      "ankle\n",
      "alive\n"
     ]
    }
   ],
   "source": [
    "topics = lda.show_topics(num_words=10, num_topics=10, formatted=False)\n",
    "\n",
    "#Print topics for Set 1\n",
    "for topic in topics:\n",
    "    print(\"Topic\",topic[0]+1,\":\")\n",
    "    for word in topic[1]:\n",
    "        print(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 :\n",
      "greatest\n",
      "dismissed\n",
      "jerk\n",
      "plenty\n",
      "theres\n",
      "j\n",
      "definately\n",
      "lived\n",
      "till\n",
      "allows\n",
      "Topic 2 :\n",
      "satisfied\n",
      "good\n",
      "intelligent\n",
      "willing\n",
      "punctual\n",
      "shows\n",
      "children\n",
      "ease\n",
      "conditions\n",
      "spends\n",
      "Topic 3 :\n",
      "extra\n",
      "mile\n",
      "puts\n",
      "charge\n",
      "whenever\n",
      "price\n",
      "samples\n",
      "request\n",
      "reads\n",
      "staffing\n",
      "Topic 4 :\n",
      "informative\n",
      "dental\n",
      "involved\n",
      "smith\n",
      "lets\n",
      "gp\n",
      "liver\n",
      "notch\n",
      "upper\n",
      "medicines\n",
      "Topic 5 :\n",
      "vegas\n",
      "las\n",
      "foot\n",
      "skin\n",
      "half\n",
      "mark\n",
      "including\n",
      "body\n",
      "comforting\n",
      "allow\n",
      "Topic 6 :\n",
      "broken\n",
      "root\n",
      "understands\n",
      "environment\n",
      "trained\n",
      "sharp\n",
      "pains\n",
      "break\n",
      "pas\n",
      "signed\n",
      "Topic 7 :\n",
      "fisher\n",
      "manor\n",
      "pulled\n",
      "faith\n",
      "hernia\n",
      "unwilling\n",
      "advance\n",
      "tummy\n",
      "obnoxious\n",
      "injured\n",
      "Topic 8 :\n",
      "spot\n",
      "manage\n",
      "nightmare\n",
      "proved\n",
      "greatful\n",
      "payment\n",
      "impersonal\n",
      "tonsils\n",
      "appeared\n",
      "judgmental\n",
      "Topic 9 :\n",
      "smart\n",
      "quite\n",
      "throat\n",
      "nose\n",
      "receptionist\n",
      "agree\n",
      "current\n",
      "customer\n",
      "tells\n",
      "manager\n",
      "Topic 10 :\n",
      "staff\n",
      "great\n",
      "time\n",
      "office\n",
      "would\n",
      "best\n",
      "recommend\n",
      "always\n",
      "care\n",
      "years\n",
      "Topic 11 :\n",
      "recomend\n",
      "solve\n",
      "students\n",
      "hurried\n",
      "medicaid\n",
      "slow\n",
      "individuals\n",
      "food\n",
      "perhaps\n",
      "valued\n",
      "Topic 12 :\n",
      "rushes\n",
      "ankle\n",
      "ego\n",
      "partner\n",
      "trustworthy\n",
      "mayo\n",
      "greedy\n",
      "impression\n",
      "taylor\n",
      "accomodating\n",
      "Topic 13 :\n",
      "lee\n",
      "dad\n",
      "father\n",
      "ms\n",
      "sucks\n",
      "miller\n",
      "recieved\n",
      "feet\n",
      "thompson\n",
      "license\n",
      "Topic 14 :\n",
      "pediatrician\n",
      "pushed\n",
      "class\n",
      "happens\n",
      "texas\n",
      "feelings\n",
      "accommodating\n",
      "injuries\n",
      "friday\n",
      "permanent\n",
      "Topic 15 :\n",
      "considerate\n",
      "migraines\n",
      "sincere\n",
      "annoyed\n",
      "via\n",
      "sleep\n",
      "forget\n",
      "hysterectomy\n",
      "sympathetic\n",
      "impatient\n",
      "Topic 16 :\n",
      "town\n",
      "difficult\n",
      "whats\n",
      "end\n",
      "refill\n",
      "idea\n",
      "zero\n",
      "provider\n",
      "stars\n",
      "school\n",
      "Topic 17 :\n",
      "ensure\n",
      "bladder\n",
      "losing\n",
      "meticulous\n",
      "qualified\n",
      "professionals\n",
      "language\n",
      "adult\n",
      "relative\n",
      "contacting\n",
      "Topic 18 :\n",
      "cosmetic\n",
      "leaves\n",
      "reschedule\n",
      "dermatologist\n",
      "page\n",
      "talented\n",
      "knowlegable\n",
      "cancelled\n",
      "ears\n",
      "rudest\n",
      "Topic 19 :\n",
      "son\n",
      "appt\n",
      "kids\n",
      "breast\n",
      "listened\n",
      "check\n",
      "meds\n",
      "due\n",
      "children\n",
      "fantastic\n",
      "Topic 20 :\n",
      "visiting\n",
      "changes\n",
      "saver\n",
      "cyst\n",
      "welcoming\n",
      "aloof\n",
      "importantly\n",
      "professionally\n",
      "encouraging\n",
      "recommends\n"
     ]
    }
   ],
   "source": [
    "topics2 = lda2.show_topics(num_topics=20,num_words=10, formatted=False)\n",
    "\n",
    "#Print topics for Set 2\n",
    "for topic in topics2:\n",
    "    print(\"Topic\",topic[0]+1,\":\")\n",
    "    for word in topic[1]:\n",
    "        print(word[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
